{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>category_1</th>\n",
       "      <th>category_2</th>\n",
       "      <th>category_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>S6pQZQocMB1WHMjTRbt77A</td>\n",
       "      <td>ejFxLGqQcWNLdNByJlIhnQ</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The place is cute and the staff was very frien...</td>\n",
       "      <td>2017-08-08 00:58:18</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Breakfast &amp; Brunch</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>WqgTKVqWVHDHjnjEsBvUgg</td>\n",
       "      <td>f7xa0p_1V9lx53iIGN5Sug</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3.0</td>\n",
       "      <td>We came on a Saturday morning after waiting a ...</td>\n",
       "      <td>2017-11-19 02:20:23</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Breakfast &amp; Brunch</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>wfJS0o2_absa6lYYuVnz4g</td>\n",
       "      <td>qdneUwCll9ADHOp7i3wq3Q</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>4.0</td>\n",
       "      <td>This place is conveniently located at English ...</td>\n",
       "      <td>2017-05-14 14:20:27</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Breakfast &amp; Brunch</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>YX2cFHDxlUfGnQ8bHPq4cA</td>\n",
       "      <td>QD9xhB-261YIQIFI5sRBtQ</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Not Impressed at all. Ordered a omelette and b...</td>\n",
       "      <td>2017-07-20 17:22:04</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Breakfast &amp; Brunch</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>yT87_j7RyUTdHMuG0hvHXA</td>\n",
       "      <td>tqJxu8-N-PWiuZn30HTwng</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Went here over the weekend,  got my sugar rush...</td>\n",
       "      <td>2017-05-16 12:58:44</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Breakfast &amp; Brunch</td>\n",
       "      <td>Food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259815</th>\n",
       "      <td>1123095</td>\n",
       "      <td>vQ8YcrMBv47IuMHpP0asKA</td>\n",
       "      <td>TLh0QKpUeT15PRSGI1uNWQ</td>\n",
       "      <td>kD03gNnQrHarCz97s1BNDQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great, fresh and authentic tasting food! We ha...</td>\n",
       "      <td>2021-11-06 23:21:44</td>\n",
       "      <td>Mandola's Italian Kitchen</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259816</th>\n",
       "      <td>1123105</td>\n",
       "      <td>8wSRJxGG2Tc5vmwj4cs69w</td>\n",
       "      <td>bCn8JIdnXyEFROm9iqQVdg</td>\n",
       "      <td>kD03gNnQrHarCz97s1BNDQ</td>\n",
       "      <td>2.0</td>\n",
       "      <td>I visited on Sunday and had a bad experience w...</td>\n",
       "      <td>2021-10-31 02:38:45</td>\n",
       "      <td>Mandola's Italian Kitchen</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259817</th>\n",
       "      <td>1123106</td>\n",
       "      <td>sc-W-A8B1Hfy72Aujp9arw</td>\n",
       "      <td>Sp2GV7D-_JLZMPQmDanzPQ</td>\n",
       "      <td>kD03gNnQrHarCz97s1BNDQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Came in for lunch with my friend. A bit confus...</td>\n",
       "      <td>2021-12-02 01:26:33</td>\n",
       "      <td>Mandola's Italian Kitchen</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259818</th>\n",
       "      <td>1123107</td>\n",
       "      <td>LF5nuJGuQYprbQZpAYJM_w</td>\n",
       "      <td>S_VUtqoT9eHYrcb4qTVdIw</td>\n",
       "      <td>kD03gNnQrHarCz97s1BNDQ</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Had a great time at Mandolas for my sons birth...</td>\n",
       "      <td>2022-01-13 02:42:17</td>\n",
       "      <td>Mandola's Italian Kitchen</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259819</th>\n",
       "      <td>1123108</td>\n",
       "      <td>LtBG04U5ZC3JO00QSZN8bw</td>\n",
       "      <td>UlIHaiR81-eR5labkP12Sw</td>\n",
       "      <td>kD03gNnQrHarCz97s1BNDQ</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Great new Italian spot! Here for soft open the...</td>\n",
       "      <td>2021-10-01 00:13:19</td>\n",
       "      <td>Mandola's Italian Kitchen</td>\n",
       "      <td>Tampa</td>\n",
       "      <td>FL</td>\n",
       "      <td>Restaurants</td>\n",
       "      <td>Grocery</td>\n",
       "      <td>Italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>259820 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0               review_id                 user_id  \\\n",
       "0                2  S6pQZQocMB1WHMjTRbt77A  ejFxLGqQcWNLdNByJlIhnQ   \n",
       "1                3  WqgTKVqWVHDHjnjEsBvUgg  f7xa0p_1V9lx53iIGN5Sug   \n",
       "2               10  wfJS0o2_absa6lYYuVnz4g  qdneUwCll9ADHOp7i3wq3Q   \n",
       "3               13  YX2cFHDxlUfGnQ8bHPq4cA  QD9xhB-261YIQIFI5sRBtQ   \n",
       "4               15  yT87_j7RyUTdHMuG0hvHXA  tqJxu8-N-PWiuZn30HTwng   \n",
       "...            ...                     ...                     ...   \n",
       "259815     1123095  vQ8YcrMBv47IuMHpP0asKA  TLh0QKpUeT15PRSGI1uNWQ   \n",
       "259816     1123105  8wSRJxGG2Tc5vmwj4cs69w  bCn8JIdnXyEFROm9iqQVdg   \n",
       "259817     1123106  sc-W-A8B1Hfy72Aujp9arw  Sp2GV7D-_JLZMPQmDanzPQ   \n",
       "259818     1123107  LF5nuJGuQYprbQZpAYJM_w  S_VUtqoT9eHYrcb4qTVdIw   \n",
       "259819     1123108  LtBG04U5ZC3JO00QSZN8bw  UlIHaiR81-eR5labkP12Sw   \n",
       "\n",
       "                   business_id  stars  \\\n",
       "0       XQfwVwDr-v0ZS3_CbbE5Xw    4.0   \n",
       "1       XQfwVwDr-v0ZS3_CbbE5Xw    3.0   \n",
       "2       XQfwVwDr-v0ZS3_CbbE5Xw    4.0   \n",
       "3       XQfwVwDr-v0ZS3_CbbE5Xw    1.0   \n",
       "4       XQfwVwDr-v0ZS3_CbbE5Xw    5.0   \n",
       "...                        ...    ...   \n",
       "259815  kD03gNnQrHarCz97s1BNDQ    5.0   \n",
       "259816  kD03gNnQrHarCz97s1BNDQ    2.0   \n",
       "259817  kD03gNnQrHarCz97s1BNDQ    4.0   \n",
       "259818  kD03gNnQrHarCz97s1BNDQ    4.0   \n",
       "259819  kD03gNnQrHarCz97s1BNDQ    5.0   \n",
       "\n",
       "                                                     text  \\\n",
       "0       The place is cute and the staff was very frien...   \n",
       "1       We came on a Saturday morning after waiting a ...   \n",
       "2       This place is conveniently located at English ...   \n",
       "3       Not Impressed at all. Ordered a omelette and b...   \n",
       "4       Went here over the weekend,  got my sugar rush...   \n",
       "...                                                   ...   \n",
       "259815  Great, fresh and authentic tasting food! We ha...   \n",
       "259816  I visited on Sunday and had a bad experience w...   \n",
       "259817  Came in for lunch with my friend. A bit confus...   \n",
       "259818  Had a great time at Mandolas for my sons birth...   \n",
       "259819  Great new Italian spot! Here for soft open the...   \n",
       "\n",
       "                       date                          name         city state  \\\n",
       "0       2017-08-08 00:58:18  Turning Point of North Wales  North Wales    PA   \n",
       "1       2017-11-19 02:20:23  Turning Point of North Wales  North Wales    PA   \n",
       "2       2017-05-14 14:20:27  Turning Point of North Wales  North Wales    PA   \n",
       "3       2017-07-20 17:22:04  Turning Point of North Wales  North Wales    PA   \n",
       "4       2017-05-16 12:58:44  Turning Point of North Wales  North Wales    PA   \n",
       "...                     ...                           ...          ...   ...   \n",
       "259815  2021-11-06 23:21:44     Mandola's Italian Kitchen        Tampa    FL   \n",
       "259816  2021-10-31 02:38:45     Mandola's Italian Kitchen        Tampa    FL   \n",
       "259817  2021-12-02 01:26:33     Mandola's Italian Kitchen        Tampa    FL   \n",
       "259818  2022-01-13 02:42:17     Mandola's Italian Kitchen        Tampa    FL   \n",
       "259819  2021-10-01 00:13:19     Mandola's Italian Kitchen        Tampa    FL   \n",
       "\n",
       "         category_1           category_2 category_3  \n",
       "0       Restaurants   Breakfast & Brunch       Food  \n",
       "1       Restaurants   Breakfast & Brunch       Food  \n",
       "2       Restaurants   Breakfast & Brunch       Food  \n",
       "3       Restaurants   Breakfast & Brunch       Food  \n",
       "4       Restaurants   Breakfast & Brunch       Food  \n",
       "...             ...                  ...        ...  \n",
       "259815  Restaurants              Grocery    Italian  \n",
       "259816  Restaurants              Grocery    Italian  \n",
       "259817  Restaurants              Grocery    Italian  \n",
       "259818  Restaurants              Grocery    Italian  \n",
       "259819  Restaurants              Grocery    Italian  \n",
       "\n",
       "[259820 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this data is based on the output of review_filtering\n",
    "data = pd.read_csv('filtered_reviews.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_valid_test_split(data, m, n):\n",
    "\n",
    "    '''\n",
    "    construct rating matrix from data\n",
    "    the columns of which represent business_id\n",
    "    the rows of which represent user_id\n",
    "    the values of whose elements represent the according ratings\n",
    "    @ data: filterd_reviews \n",
    "    @ m: counts of ratings for validation\n",
    "    @ n: counts of ratings for test\n",
    "    '''\n",
    "\n",
    "    # to construct sparse matrix\n",
    "    # train\n",
    "    train_user_id = []\n",
    "    train_business_id = []\n",
    "    train_stars = []\n",
    "    # validation\n",
    "    valid_user_id = []\n",
    "    valid_business_id = []\n",
    "    valid_stars = []\n",
    "    # train + validation\n",
    "    train_valid_user_id = []\n",
    "    train_valid_business_id = []\n",
    "    train_valid_stars = []\n",
    "    # test\n",
    "    test_user_id = []\n",
    "    test_business_id = []\n",
    "    test_stars = []\n",
    "    \n",
    "    user_id_lst = data['user_id'].unique().tolist() # rows of sparse matrix\n",
    "    busi_id_lst = data['business_id'].unique().tolist() # columns of sparse matrix\n",
    "\n",
    "    train_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "    valid_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "    train_valid_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "    test_sparse_matrix = np.zeros(shape=(len(user_id_lst), len(busi_id_lst)))\n",
    "\n",
    "    ranking_df = data[['user_id','business_id','stars','date']].groupby(['user_id'])\n",
    "    \n",
    "    for group_name, group_df in ranking_df:\n",
    "        group_df = group_df.sort_values(by='date')\n",
    "\n",
    "        # if the len(group_df) > valid_m + test_n, split the group_df as \n",
    "        # training set : group_df.iloc[:len(group_df)-m-n, :]\n",
    "        # validation set : group_df.iloc[len(group_df)-m-n:len(group_df)-n, :]\n",
    "        # test set : group_df.iloc[len(group_df)-n:, :]\n",
    "\n",
    "        # otherwise, not split the group_df\n",
    "        # keep the group_df as training set\n",
    "\n",
    "        if len(group_df) > m+n: \n",
    "\n",
    "            training_set = group_df.iloc[:len(group_df)-m-n, :]\n",
    "            train_user_id.extend(training_set.loc[:,'user_id'].tolist()) \n",
    "            train_business_id.extend(training_set.loc[:,'business_id'].tolist())\n",
    "            train_stars.extend(training_set.loc[:,'stars'].tolist())\n",
    "\n",
    "            validation_set = group_df.iloc[len(group_df)-m-n:len(group_df)-n, :]\n",
    "            valid_user_id.extend(validation_set.loc[:,'user_id'].tolist()) \n",
    "            valid_business_id.extend(validation_set.loc[:,'business_id'].tolist())\n",
    "            valid_stars.extend(validation_set.loc[:,'stars'].tolist())\n",
    "            \n",
    "            train_validation_set = group_df.iloc[:len(group_df)-n, :]\n",
    "            train_valid_user_id.extend(train_validation_set.loc[:,'user_id'].tolist()) \n",
    "            train_valid_business_id.extend(train_validation_set.loc[:,'business_id'].tolist())\n",
    "            train_valid_stars.extend(train_validation_set.loc[:,'stars'].tolist())\n",
    "\n",
    "            testing_set = group_df.iloc[len(group_df)-n:, :]\n",
    "            test_user_id.extend(testing_set.loc[:,'user_id'].tolist()) \n",
    "            test_business_id.extend(testing_set.loc[:,'business_id'].tolist())\n",
    "            test_stars.extend(testing_set.loc[:,'stars'].tolist())\n",
    "\n",
    "        else:\n",
    "            training_set = group_df\n",
    "            train_user_id.extend(training_set.loc[:,'user_id'].tolist()) \n",
    "            train_business_id.extend(training_set.loc[:,'business_id'].tolist())\n",
    "            train_stars.extend(training_set.loc[:,'stars'].tolist())\n",
    "\n",
    "    train_df = pd.DataFrame({'user_id': train_user_id, 'business_id': train_business_id, 'stars': train_stars})\n",
    "    valid_df = pd.DataFrame({'user_id': valid_user_id, 'business_id': valid_business_id, 'stars': valid_stars})\n",
    "    train_valid_df = pd.DataFrame({'user_id': train_valid_user_id, 'business_id': train_valid_business_id, 'stars': train_valid_stars})\n",
    "    test_df = pd.DataFrame({'user_id': test_user_id, 'business_id': test_business_id, 'stars': test_stars})\n",
    "\n",
    "\n",
    "    for i in range(len(train_df)):\n",
    "        ratings = train_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(train_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(train_df.iloc[i, 1]) # business_id\n",
    "        train_sparse_matrix[row_index, column_index] = ratings\n",
    "\n",
    "    for i in range(len(valid_df)):\n",
    "        ratings = valid_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(valid_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(valid_df.iloc[i, 1]) # business_id\n",
    "        valid_sparse_matrix[row_index, column_index] = ratings\n",
    "        \n",
    "    for i in range(len(train_valid_df)):\n",
    "        ratings = train_valid_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(train_valid_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(train_valid_df.iloc[i, 1]) # business_id\n",
    "        train_valid_sparse_matrix[row_index, column_index] = ratings\n",
    "        \n",
    "    for i in range(len(test_df)):\n",
    "        ratings = test_df.iloc[i, 2] # stars\n",
    "        row_index = user_id_lst.index(test_df.iloc[i, 0]) # user_id\n",
    "        column_index = busi_id_lst.index(test_df.iloc[i, 1]) # business_id\n",
    "        test_sparse_matrix[row_index, column_index] = ratings\n",
    "\n",
    "    # calculate sparstiy of the matrix\n",
    "    train_sparsity = 1 - np.count_nonzero(train_sparse_matrix)/ (train_sparse_matrix.shape[0] * train_sparse_matrix.shape[1])\n",
    "    valid_sparsity = 1 - np.count_nonzero(valid_sparse_matrix)/ (valid_sparse_matrix.shape[0] * valid_sparse_matrix.shape[1])\n",
    "    train_valid_sparsity = 1 - np.count_nonzero(train_valid_sparse_matrix)/ (train_valid_sparse_matrix.shape[0] * train_valid_sparse_matrix.shape[1])\n",
    "    test_sparsity = 1 - np.count_nonzero(test_sparse_matrix)/ (test_sparse_matrix.shape[0] * test_sparse_matrix.shape[1])\n",
    "\n",
    "    train_sparsity *= 100\n",
    "    valid_sparsity *=100\n",
    "    train_valid_sparse_matrix *= 100\n",
    "    test_sparsity *= 100\n",
    "\n",
    "    print (f'{len(user_id_lst)} users')\n",
    "    print (f'{len(busi_id_lst)} business')\n",
    "\n",
    "    print (f'Train_rating_matrix Sparsity: {round(train_sparsity,4)}%')\n",
    "    print (f'Valid_rating_matrix Sparsity: {round(valid_sparsity,4)}%')\n",
    "    print(f'Test_rating_matrix Sparsity:  {round(test_sparsity,4)}%')\n",
    "\n",
    "\n",
    "    return train_sparse_matrix, valid_sparse_matrix, train_valid_sparse_matrix, test_sparse_matrix, \\\n",
    "           train_df, valid_df, train_valid_df, test_df, \\\n",
    "           user_id_lst, busi_id_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25420 users\n",
      "4312 business\n",
      "Train_rating_matrix Sparsity: 99.8088%\n",
      "Valid_rating_matrix Sparsity: 99.9771%\n",
      "Test_rating_matrix Sparsity:  99.9771%\n"
     ]
    }
   ],
   "source": [
    "train_sparse_matrix, valid_sparse_matrix, train_valid_sparse_matrix, test_sparse_matrix, \\\n",
    "           train_df, valid_df, train_valid_df, test_df, \\\n",
    "           user_id_lst, busi_id_lst = train_valid_test_split(data=data, m=1, n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.save('train_sparse_matrix.npy', train_sparse_matrix)\n",
    "np.save('valid_sparse_matrix.npy', valid_sparse_matrix)\n",
    "np.save('test_sparse_matrix.npy', test_sparse_matrix)\n",
    "np.save('train_valid_sparse_matrix.npy', train_valid_sparse_matrix)\n",
    "\n",
    "np.save('user_id_lst.npy', user_id_lst)\n",
    "np.save('busi_id_lst.npy', busi_id_lst)\n",
    "\n",
    "train_df.to_pickle('train_df.pkl')\n",
    "valid_df.to_pickle('valid_df.pkl')\n",
    "test_df.to_pickle('test_df.pkl')\n",
    "train_valid_df.to_pickle('train_valid_df.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25420, 4312)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25420, 4312)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sparse_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25420, 4312)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_valid_sparse_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
